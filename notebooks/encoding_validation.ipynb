{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Encoding Validation\n",
        "\n",
        "This notebook validates the feature encoding by:\n",
        "1. Loading the saved encoder (created by `scripts/apply_encoding.py`)\n",
        "2. Loading the encoded dataset\n",
        "3. Verifying encoding properties for each categorical feature\n",
        "4. Checking that original categorical columns were removed/replaced\n",
        "5. Checking for data leakage using the `split_group` column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, str(Path.cwd().parent/\"src\"))\n",
        "\n",
        "from features.encoding import FeatureEncoder, CATEGORICAL_FEATURES\n",
        "from sklearn.preprocessing import OneHotEncoder, TargetEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Encoder and Encoded Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder loaded: encoder.joblib\n",
            "    Features to encode: 3\n",
            "======================================================================\n",
            "Feature: countries - Encoder: MultiLabelBinarizer\n",
            "Feature: pnns_groups_1 - Encoder: OneHotEncoder\n",
            "Feature: pnns_groups_2 - Encoder: TargetEncoder\n",
            "\n",
            "Loaded Encoded Dataset with shape: (96132, 40)\n",
            "======================================================================\n",
            "Found 'split_group' column for train/test tracking\n"
          ]
        }
      ],
      "source": [
        "# Load encoder\n",
        "models_dir = Path('../models')\n",
        "encoder_path = models_dir / 'encoder.joblib'\n",
        "\n",
        "if not encoder_path.exists():\n",
        "    raise FileNotFoundError(\"No encoder found. Run 'scripts/apply_encoding.py' first\")\n",
        "\n",
        "encoder = FeatureEncoder.load(str(encoder_path))\n",
        "print(f\"Encoder loaded: {encoder_path.name}\")\n",
        "print(f\"    Features to encode: {len(CATEGORICAL_FEATURES)}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Show encoder type for each feature\n",
        "for feature in CATEGORICAL_FEATURES:\n",
        "    if feature in encoder.encoders:\n",
        "        encoder_type = encoder.encoders[feature].__class__.__name__\n",
        "        print(f\"Feature: {feature} - Encoder: {encoder_type}\")\n",
        "    else:\n",
        "        print(f\"Feature: {feature} - Encoder: NOT FITTED (feature not in training data)\")\n",
        "\n",
        "# Load encoded dataset if it exists\n",
        "encoded_file = Path('../data/processed/openfoodfacts_encoded.csv')\n",
        "if encoded_file.exists():\n",
        "    df_encoded = pd.read_csv(encoded_file)\n",
        "    print(f\"\\nLoaded Encoded Dataset with shape: {df_encoded.shape}\")\n",
        "    \n",
        "    # Check if split_group column exists\n",
        "    if 'split_group' in df_encoded.columns:\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Found 'split_group' column for train/test tracking\")\n",
        "    else:\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Warning: 'split_group' column not found\")\n",
        "else:\n",
        "    print(f\"\\nNo Encoded Dataset found. Run 'scripts/apply_encoding.py' first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Split Data Using split_group Column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using 'split_group' column for splitting\n",
            "  Train: 76,905 | Test: 19,227\n"
          ]
        }
      ],
      "source": [
        "# Split using split_group column if available\n",
        "if 'split_group' in df_encoded.columns:\n",
        "    train_mask = df_encoded['split_group'] == 'train'\n",
        "    X_train_encoded = df_encoded[train_mask].drop(columns=['split_group'], errors='ignore')\n",
        "    X_test_encoded = df_encoded[~train_mask].drop(columns=['split_group'], errors='ignore')\n",
        "    print(f\"✓ Using 'split_group' column for splitting\")\n",
        "    print(f\"  Train: {len(X_train_encoded):,} | Test: {len(X_test_encoded):,}\")\n",
        "else:\n",
        "    # Fallback: recreate split (not ideal, but works)\n",
        "    print(\"⚠ 'split_group' not found. Recreating split...\")\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    df_original = pd.read_csv('../data/processed/openfoodfacts_scaled.csv')\n",
        "    X = df_encoded.drop(columns=['nutriscore_grade', 'code'], errors='ignore')\n",
        "    y = df_original['nutriscore_grade'] if 'nutriscore_grade' in df_original.columns else None\n",
        "    X_train_encoded, X_test_encoded, _, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    print(f\"  Train: {len(X_train_encoded):,} | Test: {len(X_test_encoded):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verify Encoding Properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding Validation Summary:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Encoder Type</th>\n",
              "      <th>Status</th>\n",
              "      <th>Columns Created</th>\n",
              "      <th>Original Removed</th>\n",
              "      <th>Binary Values</th>\n",
              "      <th>Rows Sum to 1</th>\n",
              "      <th>Is Numeric</th>\n",
              "      <th>In Range [0,1]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pnns_groups_1</td>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>✓ OK</td>\n",
              "      <td>11</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pnns_groups_2</td>\n",
              "      <td>TargetEncoder</td>\n",
              "      <td>✓ OK</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feature   Encoder Type Status  Columns Created  Original Removed  \\\n",
              "0  pnns_groups_1  OneHotEncoder   ✓ OK               11              True   \n",
              "1  pnns_groups_2  TargetEncoder   ✓ OK                1             False   \n",
              "\n",
              "  Binary Values Rows Sum to 1 Is Numeric In Range [0,1]  \n",
              "0          True          True        NaN            NaN  \n",
              "1           NaN           NaN       True           True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "summary_data = []\n",
        "\n",
        "for feature in CATEGORICAL_FEATURES:\n",
        "    if feature not in encoder.encoders:\n",
        "        summary_data.append({\n",
        "            'Feature': feature,\n",
        "            'Encoder Type': 'NOT FITTED',\n",
        "            'Status': 'Feature not in training data',\n",
        "            'Columns Created': 0\n",
        "        })\n",
        "        continue\n",
        "    \n",
        "    encoder_obj = encoder.encoders[feature]\n",
        "    encoder_type = encoder_obj.__class__.__name__\n",
        "    \n",
        "    if isinstance(encoder_obj, OneHotEncoder):\n",
        "        # OneHotEncoder creates multiple columns\n",
        "        encoded_cols = [col for col in X_train_encoded.columns if col.startswith(feature + '_')]\n",
        "        n_cols = len(encoded_cols)\n",
        "        \n",
        "        # Check that original column is removed\n",
        "        original_removed = feature not in X_train_encoded.columns\n",
        "        \n",
        "        # Check OneHotEncoder properties (binary columns, sum to 1)\n",
        "        if n_cols > 0:\n",
        "            sample_col = encoded_cols[0]\n",
        "            is_binary = X_train_encoded[encoded_cols].isin([0, 1]).all().all()\n",
        "            row_sums = X_train_encoded[encoded_cols].sum(axis=1)\n",
        "            sums_to_one = row_sums.isin([0, 1]).all()  # Each row should have exactly one 1\n",
        "        else:\n",
        "            is_binary = False\n",
        "            sums_to_one = False\n",
        "        \n",
        "        status = \"✓ OK\" if (original_removed and is_binary and sums_to_one) else \"⚠ ISSUES\"\n",
        "        \n",
        "        summary_data.append({\n",
        "            'Feature': feature,\n",
        "            'Encoder Type': encoder_type,\n",
        "            'Status': status,\n",
        "            'Columns Created': n_cols,\n",
        "            'Original Removed': original_removed,\n",
        "            'Binary Values': is_binary,\n",
        "            'Rows Sum to 1': sums_to_one\n",
        "        })\n",
        "    \n",
        "    elif isinstance(encoder_obj, TargetEncoder):\n",
        "        # TargetEncoder replaces the original column with numeric values\n",
        "        column_exists = feature in X_train_encoded.columns\n",
        "        original_removed = False  # TargetEncoder keeps the same column name\n",
        "        \n",
        "        if column_exists:\n",
        "            # Check that values are numeric and in reasonable range\n",
        "            values = X_train_encoded[feature]\n",
        "            is_numeric = pd.api.types.is_numeric_dtype(values)\n",
        "            in_range = (values.min() >= 0) and (values.max() <= 1)  # TargetEncoder outputs probabilities\n",
        "        else:\n",
        "            is_numeric = False\n",
        "            in_range = False\n",
        "        \n",
        "        status = \"✓ OK\" if (column_exists and is_numeric and in_range) else \"⚠ ISSUES\"\n",
        "        \n",
        "        summary_data.append({\n",
        "            'Feature': feature,\n",
        "            'Encoder Type': encoder_type,\n",
        "            'Status': status,\n",
        "            'Columns Created': 1,\n",
        "            'Original Removed': original_removed,\n",
        "            'Is Numeric': is_numeric,\n",
        "            'In Range [0,1]': in_range\n",
        "        })\n",
        "\n",
        "check_df = pd.DataFrame(summary_data)\n",
        "print(\"Encoding Validation Summary:\\n\")\n",
        "display(check_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Check Original Columns Removed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Column Removal Check:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>In Encoded Dataset</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>countries</td>\n",
              "      <td>False</td>\n",
              "      <td>⚠ UNKNOWN ENCODER TYPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pnns_groups_1</td>\n",
              "      <td>False</td>\n",
              "      <td>✓ OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pnns_groups_2</td>\n",
              "      <td>True</td>\n",
              "      <td>✓ OK (replaced with numeric)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feature  In Encoded Dataset                        Status\n",
              "0      countries               False        ⚠ UNKNOWN ENCODER TYPE\n",
              "1  pnns_groups_1               False                          ✓ OK\n",
              "2  pnns_groups_2                True  ✓ OK (replaced with numeric)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check that original categorical columns are removed (for OneHotEncoder) or replaced (for TargetEncoder)\n",
        "removal_check = []\n",
        "\n",
        "for feature in CATEGORICAL_FEATURES:\n",
        "    if feature not in encoder.encoders:\n",
        "        removal_check.append({\n",
        "            'Feature': feature,\n",
        "            'In Encoded Dataset': feature in df_encoded.columns,\n",
        "            'Status': 'N/A (not encoded)'\n",
        "        })\n",
        "        continue\n",
        "    \n",
        "    encoder_obj = encoder.encoders[feature]\n",
        "    in_dataset = feature in df_encoded.columns\n",
        "    \n",
        "    if isinstance(encoder_obj, OneHotEncoder):\n",
        "        # OneHotEncoder should remove original column\n",
        "        status = \"✓ OK\" if not in_dataset else \"⚠ ERROR: Original column still present\"\n",
        "    elif isinstance(encoder_obj, TargetEncoder):\n",
        "        # TargetEncoder replaces original with numeric values\n",
        "        if in_dataset:\n",
        "            is_numeric = pd.api.types.is_numeric_dtype(df_encoded[feature])\n",
        "            status = \"✓ OK (replaced with numeric)\" if is_numeric else \"⚠ ERROR: Not numeric\"\n",
        "        else:\n",
        "            status = \"⚠ ERROR: Column missing\"\n",
        "    else:\n",
        "        status = \"⚠ UNKNOWN ENCODER TYPE\"\n",
        "    \n",
        "    removal_check.append({\n",
        "        'Feature': feature,\n",
        "        'In Encoded Dataset': in_dataset,\n",
        "        'Status': status\n",
        "    })\n",
        "\n",
        "print(\"Original Column Removal Check:\\n\")\n",
        "display(pd.DataFrame(removal_check))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Check Data Leakage Prevention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA LEAKAGE CHECK (Target: NO for all rows)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Encoder</th>\n",
              "      <th>Test Set Mean Diff</th>\n",
              "      <th>Leakage Detected</th>\n",
              "      <th>Note</th>\n",
              "      <th>Train Mean</th>\n",
              "      <th>Test Mean</th>\n",
              "      <th>Mean Diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pnns_groups_1</td>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>✅ NO</td>\n",
              "      <td>Check if test patterns match train exactly</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pnns_groups_2</td>\n",
              "      <td>TargetEncoder</td>\n",
              "      <td>NaN</td>\n",
              "      <td>⚠️ YES</td>\n",
              "      <td>TargetEncoder uses target info, some similarit...</td>\n",
              "      <td>0.1496</td>\n",
              "      <td>0.1502</td>\n",
              "      <td>0.0006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feature        Encoder Test Set Mean Diff Leakage Detected  \\\n",
              "0  pnns_groups_1  OneHotEncoder             0.0018             ✅ NO   \n",
              "1  pnns_groups_2  TargetEncoder                NaN           ⚠️ YES   \n",
              "\n",
              "                                                Note Train Mean Test Mean  \\\n",
              "0         Check if test patterns match train exactly        NaN       NaN   \n",
              "1  TargetEncoder uses target info, some similarit...     0.1496    0.1502   \n",
              "\n",
              "  Mean Diff  \n",
              "0       NaN  \n",
              "1    0.0006  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check for data leakage by comparing train/test statistics\n",
        "leakage_data = []\n",
        "\n",
        "for feature in CATEGORICAL_FEATURES:\n",
        "    if feature not in encoder.encoders:\n",
        "        continue\n",
        "    \n",
        "    encoder_obj = encoder.encoders[feature]\n",
        "    \n",
        "    if isinstance(encoder_obj, OneHotEncoder):\n",
        "        # For OneHotEncoder, check encoded columns\n",
        "        encoded_cols = [col for col in X_train_encoded.columns if col.startswith(feature + '_')]\n",
        "        \n",
        "        if len(encoded_cols) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Check if test set has categories not seen in training\n",
        "        train_means = X_train_encoded[encoded_cols].mean()\n",
        "        test_means = X_test_encoded[encoded_cols].mean()\n",
        "        \n",
        "        # Check for suspicious patterns (test set should have similar distribution)\n",
        "        # If test set has perfect 0/1 patterns that match training exactly, might indicate leakage\n",
        "        mean_diff = (train_means - test_means).abs().mean()\n",
        "        \n",
        "        # Also check for unknown categories (should be handled by handle_unknown=\"ignore\")\n",
        "        train_max = X_train_encoded[encoded_cols].max().max()\n",
        "        test_max = X_test_encoded[encoded_cols].max().max()\n",
        "        \n",
        "        # Leakage would show as test set having identical patterns to train\n",
        "        is_suspicious = mean_diff < 0.001 and train_max == test_max == 1.0\n",
        "        \n",
        "        leakage_data.append({\n",
        "            'Feature': feature,\n",
        "            'Encoder': 'OneHotEncoder',\n",
        "            'Test Set Mean Diff': f\"{mean_diff:.4f}\",\n",
        "            'Leakage Detected': \"⚠️ YES\" if is_suspicious else \"✅ NO\",\n",
        "            'Note': 'Check if test patterns match train exactly'\n",
        "        })\n",
        "    \n",
        "    elif isinstance(encoder_obj, TargetEncoder):\n",
        "        # For TargetEncoder, check that test values are in reasonable range\n",
        "        if feature not in X_test_encoded.columns:\n",
        "            continue\n",
        "        \n",
        "        train_values = X_train_encoded[feature]\n",
        "        test_values = X_test_encoded[feature]\n",
        "        \n",
        "        train_mean = train_values.mean()\n",
        "        test_mean = test_values.mean()\n",
        "        mean_diff = abs(train_mean - test_mean)\n",
        "        \n",
        "        # TargetEncoder should produce similar distributions\n",
        "        # Very similar means might indicate leakage, but some similarity is expected\n",
        "        is_suspicious = mean_diff < 0.001  # Very suspicious if identical\n",
        "        \n",
        "        leakage_data.append({\n",
        "            'Feature': feature,\n",
        "            'Encoder': 'TargetEncoder',\n",
        "            'Train Mean': f\"{train_mean:.4f}\",\n",
        "            'Test Mean': f\"{test_mean:.4f}\",\n",
        "            'Mean Diff': f\"{mean_diff:.4f}\",\n",
        "            'Leakage Detected': \"⚠️ YES\" if is_suspicious else \"✅ NO\",\n",
        "            'Note': 'TargetEncoder uses target info, some similarity expected'\n",
        "        })\n",
        "\n",
        "if leakage_data:\n",
        "    print(\"DATA LEAKAGE CHECK (Target: NO for all rows)\\n\")\n",
        "    display(pd.DataFrame(leakage_data))\n",
        "else:\n",
        "    print(\"No categorical features encoded to check for leakage.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "VALIDATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Encoder loaded: encoder.joblib\n",
            "Features to encode: 3\n",
            "\n",
            "Encoder distribution:\n",
            "  MultiLabelBinarizer: 1 feature(s)\n",
            "  OneHotEncoder: 1 feature(s)\n",
            "  TargetEncoder: 1 feature(s)\n",
            "\n",
            "Dataset:\n",
            "  Train: 76,905 samples\n",
            "  Test:  19,227 samples\n",
            "  Total columns: 40\n",
            "\n",
            "✓ Encoding validation completed\n",
            "✓ Ready for model training\n",
            "✓ No major issues detected\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"VALIDATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nEncoder loaded: {encoder_path.name}\")\n",
        "print(f\"Features to encode: {len(CATEGORICAL_FEATURES)}\")\n",
        "\n",
        "# Count encoder types\n",
        "encoder_types = {}\n",
        "for feature in CATEGORICAL_FEATURES:\n",
        "    if feature in encoder.encoders:\n",
        "        enc_type = encoder.encoders[feature].__class__.__name__\n",
        "        encoder_types[enc_type] = encoder_types.get(enc_type, 0) + 1\n",
        "\n",
        "print(f\"\\nEncoder distribution:\")\n",
        "for enc_type, count in encoder_types.items():\n",
        "    print(f\"  {enc_type}: {count} feature(s)\")\n",
        "\n",
        "print(f\"\\nDataset:\")\n",
        "print(f\"  Train: {len(X_train_encoded):,} samples\")\n",
        "print(f\"  Test:  {len(X_test_encoded):,} samples\")\n",
        "print(f\"  Total columns: {len(df_encoded.columns)}\")\n",
        "\n",
        "# Check for issues\n",
        "issues = []\n",
        "for feature in CATEGORICAL_FEATURES:\n",
        "    if feature not in encoder.encoders:\n",
        "        issues.append(f\"  - {feature}: Not encoded (not in training data)\")\n",
        "\n",
        "if issues:\n",
        "    print(f\"\\n⚠ Issues found:\")\n",
        "    for issue in issues:\n",
        "        print(issue)\n",
        "else:\n",
        "    print(f\"\\n✓ Encoding validation completed\")\n",
        "    print(f\"✓ Ready for model training\")\n",
        "    print(f\"✓ No major issues detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"D:\\cesare\\Documents\\ML_project\\ml-project-2025\\data\\processed\\openfoodfacts_encoded.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>product_name</th>\n",
              "      <th>brands</th>\n",
              "      <th>categories</th>\n",
              "      <th>energy_100g</th>\n",
              "      <th>energy-kcal_100g</th>\n",
              "      <th>fat_100g</th>\n",
              "      <th>saturated-fat_100g</th>\n",
              "      <th>carbohydrates_100g</th>\n",
              "      <th>sugars_100g</th>\n",
              "      <th>...</th>\n",
              "      <th>pnns_groups_1_Composite foods</th>\n",
              "      <th>pnns_groups_1_Fat and sauces</th>\n",
              "      <th>pnns_groups_1_Fish Meat Eggs</th>\n",
              "      <th>pnns_groups_1_Fruits and vegetables</th>\n",
              "      <th>pnns_groups_1_Milk and dairy products</th>\n",
              "      <th>pnns_groups_1_Salty snacks</th>\n",
              "      <th>pnns_groups_1_Sugary snacks</th>\n",
              "      <th>pnns_groups_1_unknown</th>\n",
              "      <th>nutriscore_grade</th>\n",
              "      <th>split_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2201130003253</td>\n",
              "      <td>Lomo embuchado</td>\n",
              "      <td>Realvalle</td>\n",
              "      <td>Productos a base de carne, Carnes, Embutidos</td>\n",
              "      <td>946.0</td>\n",
              "      <td>-0.201939</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.031313</td>\n",
              "      <td>-0.999668</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>e</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663811146427</td>\n",
              "      <td>Farçou façon grand mère pommes de terre sauce ...</td>\n",
              "      <td>Cellier Sarlat</td>\n",
              "      <td>Plats préparés</td>\n",
              "      <td>519.0</td>\n",
              "      <td>-0.792792</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.029293</td>\n",
              "      <td>-0.768744</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>c</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9003740065606</td>\n",
              "      <td>Bio-Karottensaft</td>\n",
              "      <td>Ja! Natürlich</td>\n",
              "      <td>Pflanzliche Lebensmittel und Getränke, Getränk...</td>\n",
              "      <td>163.0</td>\n",
              "      <td>-1.285168</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>-0.691769</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>e</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8431876251883</td>\n",
              "      <td>Macedonia de verduras</td>\n",
              "      <td>Carrefour</td>\n",
              "      <td>Alimentos y bebidas de origen vegetal, Aliment...</td>\n",
              "      <td>180.0</td>\n",
              "      <td>-1.261998</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.739420</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>c</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8014745044207</td>\n",
              "      <td>Burrata</td>\n",
              "      <td>Murgella</td>\n",
              "      <td>Latticini, Cibi fermentati, Prodotti lattiero-...</td>\n",
              "      <td>908.0</td>\n",
              "      <td>-0.254073</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>-0.968512</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>c</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            code                                       product_name  \\\n",
              "0  2201130003253                                     Lomo embuchado   \n",
              "1  3663811146427  Farçou façon grand mère pommes de terre sauce ...   \n",
              "2  9003740065606                                   Bio-Karottensaft   \n",
              "3  8431876251883                              Macedonia de verduras   \n",
              "4  8014745044207                                            Burrata   \n",
              "\n",
              "           brands                                         categories  \\\n",
              "0       Realvalle       Productos a base de carne, Carnes, Embutidos   \n",
              "1  Cellier Sarlat                                     Plats préparés   \n",
              "2   Ja! Natürlich  Pflanzliche Lebensmittel und Getränke, Getränk...   \n",
              "3       Carrefour  Alimentos y bebidas de origen vegetal, Aliment...   \n",
              "4        Murgella  Latticini, Cibi fermentati, Prodotti lattiero-...   \n",
              "\n",
              "   energy_100g  energy-kcal_100g  fat_100g  saturated-fat_100g  \\\n",
              "0        946.0         -0.201939     0.080            0.031313   \n",
              "1        519.0         -0.792792     0.078            0.029293   \n",
              "2        163.0         -1.285168     0.005            0.001010   \n",
              "3        180.0         -1.261998     0.000            0.000000   \n",
              "4        908.0         -0.254073     0.180            0.121212   \n",
              "\n",
              "   carbohydrates_100g  sugars_100g  ...  pnns_groups_1_Composite foods  \\\n",
              "0           -0.999668       0.0040  ...                            0.0   \n",
              "1           -0.768744       0.0060  ...                            1.0   \n",
              "2           -0.691769       0.0880  ...                            0.0   \n",
              "3           -0.739420       0.0100  ...                            1.0   \n",
              "4           -0.968512       0.0125  ...                            0.0   \n",
              "\n",
              "   pnns_groups_1_Fat and sauces  pnns_groups_1_Fish Meat Eggs  \\\n",
              "0                           0.0                           1.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   pnns_groups_1_Fruits and vegetables  pnns_groups_1_Milk and dairy products  \\\n",
              "0                                  0.0                                    0.0   \n",
              "1                                  0.0                                    0.0   \n",
              "2                                  0.0                                    0.0   \n",
              "3                                  0.0                                    0.0   \n",
              "4                                  0.0                                    1.0   \n",
              "\n",
              "   pnns_groups_1_Salty snacks pnns_groups_1_Sugary snacks  \\\n",
              "0                         0.0                         0.0   \n",
              "1                         0.0                         0.0   \n",
              "2                         0.0                         0.0   \n",
              "3                         0.0                         0.0   \n",
              "4                         0.0                         0.0   \n",
              "\n",
              "   pnns_groups_1_unknown  nutriscore_grade  split_group  \n",
              "0                    0.0                 e        train  \n",
              "1                    0.0                 c        train  \n",
              "2                    0.0                 e         test  \n",
              "3                    0.0                 c        train  \n",
              "4                    0.0                 c         test  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2=pd.read_csv(\"D:\\cesare\\Documents\\ML_project\\ml-project-2025\\data\\processed\\openfoodfacts_scaled.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "countries\n",
              "France            29323\n",
              "United States     25302\n",
              "Germany            6408\n",
              "Spain              5872\n",
              "Italy              5374\n",
              "United Kingdom     2745\n",
              "unknown            2549\n",
              "Switzerland        1875\n",
              "Belgium            1601\n",
              "Canada             1342\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['countries'].value_counts().head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "machine_learning_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
