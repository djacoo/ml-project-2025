{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4a229f",
   "metadata": {},
   "source": [
    "# Feature Scaling Validation\n",
    "\n",
    "This notebook validates the feature scaling by:\n",
    "1. Loading the saved scaler (created by `scripts/apply_scaling.py`)\n",
    "2. Loading the scaled dataset (or applying scaling)\n",
    "3. Verifying scaling properties for each feature\n",
    "4. Checking for data leakage using the `split_group` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d499c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent/\"src\"))\n",
    "\n",
    "from features.scaling import FeatureScaler, NUMERICAL_FEATURES\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7b81f",
   "metadata": {},
   "source": [
    "## 1. Load Scaler and Scaled Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fd79560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded: scaler.joblib\n",
      "    Method: AUTO\n",
      "    Skew threshold: 1.0\n",
      "    Features: 9\n",
      "======================================================================\n",
      "Feature: energy-kcal_100g - Scaler: StandardScaler()\n",
      "Feature: fat_100g - Scaler: MinMaxScaler()\n",
      "Feature: saturated-fat_100g - Scaler: MinMaxScaler()\n",
      "Feature: carbohydrates_100g - Scaler: StandardScaler()\n",
      "Feature: sugars_100g - Scaler: MinMaxScaler()\n",
      "Feature: fiber_100g - Scaler: MinMaxScaler()\n",
      "Feature: proteins_100g - Scaler: MinMaxScaler()\n",
      "Feature: salt_100g - Scaler: MinMaxScaler()\n",
      "Feature: additives_n - Scaler: MinMaxScaler()\n",
      "Loaded Scaled Dataset with shape: (96132, 21)\n",
      "======================================================================\n",
      "Found 'split_group' column for train/test tracking\n"
     ]
    }
   ],
   "source": [
    "# Load scaler\n",
    "models_dir = Path('../models')\n",
    "scaler_path = models_dir / 'scaler.joblib'\n",
    "\n",
    "if not scaler_path.exists():\n",
    "    raise FileNotFoundError(\"No scaler found. Run 'scripts/apply_scaling.py' first\")\n",
    "\n",
    "scaler = FeatureScaler.load(str(scaler_path))\n",
    "print(f\"Scaler loaded: {scaler_path.name}\")\n",
    "print(f\"    Method: {scaler.method.upper()}\")\n",
    "print(f\"    Skew threshold: {scaler.skew_threshold}\")\n",
    "print(f\"    Features: {len(NUMERICAL_FEATURES)}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine scaler type for each feature (for 'auto' method)\n",
    "scaler_types = {}\n",
    "if scaler.method == 'auto':\n",
    "    for feature in NUMERICAL_FEATURES:\n",
    "        print(f\"Feature: {feature} - Scaler: {scaler.scalers[feature]}\")\n",
    "else:\n",
    "# Print the method field otherwise\n",
    "    print(scaler.method)\n",
    "\n",
    "# Load scaled dataset if it exists, otherwise load original and apply scaling\n",
    "scaled_file = Path('../data/processed/openfoodfacts_scaled.csv')\n",
    "if scaled_file.exists():\n",
    "    df_scaled = pd.read_csv(scaled_file)\n",
    "    print(f\"Loaded Scaled Dataset with shape: {df_scaled.shape}\")\n",
    "    \n",
    "    # Check if split_group column exists\n",
    "    if 'split_group' in df_scaled.columns:\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Found 'split_group' column for train/test tracking\")\n",
    "    else:\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Warning: 'split_group' column not found\")\n",
    "else:\n",
    "    print(f\"\\n No Scaled Dataset found. Run 'scripts/apply_scaling.py' first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fee7d",
   "metadata": {},
   "source": [
    "## 2. Split Data Using split_group Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73ddaa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using 'split_group' column for splitting\n",
      "  Train: 76,905 | Test: 19,227\n"
     ]
    }
   ],
   "source": [
    "# Split using split_group column if available\n",
    "if 'split_group' in df_scaled.columns:\n",
    "    train_mask = df_scaled['split_group'] == 'train'\n",
    "    X_train_scaled = df_scaled[train_mask].drop(columns=['split_group'], errors='ignore')\n",
    "    X_test_scaled = df_scaled[~train_mask].drop(columns=['split_group'], errors='ignore')\n",
    "    print(f\"✓ Using 'split_group' column for splitting\")\n",
    "    print(f\"  Train: {len(X_train_scaled):,} | Test: {len(X_test_scaled):,}\")\n",
    "else:\n",
    "    # Fallback: recreate split (not ideal, but works)\n",
    "    print(\"⚠ 'split_group' not found. Recreating split...\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_original = pd.read_csv('../data/processed/openfoodfacts_cleaned.csv')\n",
    "    X = df_scaled.drop(columns=['nutriscore_grade', 'code'])\n",
    "    y = df_original['nutriscore_grade']\n",
    "    X_train_scaled, X_test_scaled, _, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"  Train: {len(X_train_scaled):,} | Test: {len(X_test_scaled):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2afd0a",
   "metadata": {},
   "source": [
    "## 3. Verify Scaling Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e835864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Strategy: AUTO\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler Used</th>\n",
       "      <th>Sanity Check</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Mean: 0.0 | Std: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat_100g</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Mean: 0.0 | Std: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugars_100g</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiber_100g</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proteins_100g</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salt_100g</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additives_n</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Scaler Used          Sanity Check\n",
       "Feature                                                 \n",
       "energy-kcal_100g    StandardScaler  Mean: 0.0 | Std: 1.0\n",
       "fat_100g              MinMaxScaler   Min: 0.0 | Max: 1.0\n",
       "saturated-fat_100g    MinMaxScaler   Min: 0.0 | Max: 1.0\n",
       "carbohydrates_100g  StandardScaler  Mean: 0.0 | Std: 1.0\n",
       "sugars_100g           MinMaxScaler   Min: 0.0 | Max: 1.0\n",
       "fiber_100g            MinMaxScaler   Min: 0.0 | Max: 1.0\n",
       "proteins_100g         MinMaxScaler   Min: 0.0 | Max: 1.0\n",
       "salt_100g             MinMaxScaler   Min: 0.0 | Max: 1.0\n",
       "additives_n           MinMaxScaler   Min: 0.0 | Max: 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_data = []\n",
    "\n",
    "for col in NUMERICAL_FEATURES:\n",
    "    series = X_train_scaled[col]\n",
    "    scaler_type = scaler.scalers[col].__class__.__name__\n",
    "    \n",
    "    if scaler_type == 'MinMaxScaler':\n",
    "        # In MinMax we just check the bounds\n",
    "        check = \"Min: \" + str(round(series.min(), 2)) + \" | Max: \" + str(round(series.max(), 2))  \n",
    "    elif scaler_type == 'StandardScaler':\n",
    "        # In Standard we check the mean and std\n",
    "        check = \"Mean: \" + str(round(series.mean(), 2)) + \" | Std: \" + str(round(series.std(), 2))\n",
    "    summary_data.append({\n",
    "        'Feature': col,\n",
    "        'Scaler Used': scaler_type,\n",
    "        'Sanity Check': check\n",
    "    })\n",
    "\n",
    "check_df = pd.DataFrame(summary_data).set_index('Feature')\n",
    "print(f\"Global Strategy: {scaler.method.upper()}\\n\")\n",
    "display(check_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8205eb",
   "metadata": {},
   "source": [
    "## 4. Check Data Leakage Prevention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48b6d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LEAKAGE CHECK (Target: NO for all rows)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Test Set Stats</th>\n",
       "      <th>Leakage Detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energy-kcal_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Mean: -0.0 | Std: 1.07</td>\n",
       "      <td>✅ NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fat_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "      <td>⚠️ YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saturated-fat_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 0.7</td>\n",
       "      <td>✅ NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carbohydrates_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Mean: -0.01 | Std: 1.0</td>\n",
       "      <td>⚠️ YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sugars_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 1.0</td>\n",
       "      <td>⚠️ YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fiber_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 0.92</td>\n",
       "      <td>✅ NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>proteins_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 0.9</td>\n",
       "      <td>✅ NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>salt_100g</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 0.99</td>\n",
       "      <td>✅ NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>additives_n</td>\n",
       "      <td>str</td>\n",
       "      <td>Min: 0.0 | Max: 0.74</td>\n",
       "      <td>✅ NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature Scaler          Test Set Stats Leakage Detected\n",
       "0    energy-kcal_100g    str  Mean: -0.0 | Std: 1.07             ✅ NO\n",
       "1            fat_100g    str     Min: 0.0 | Max: 1.0           ⚠️ YES\n",
       "2  saturated-fat_100g    str     Min: 0.0 | Max: 0.7             ✅ NO\n",
       "3  carbohydrates_100g    str  Mean: -0.01 | Std: 1.0           ⚠️ YES\n",
       "4         sugars_100g    str     Min: 0.0 | Max: 1.0           ⚠️ YES\n",
       "5          fiber_100g    str    Min: 0.0 | Max: 0.92             ✅ NO\n",
       "6       proteins_100g    str     Min: 0.0 | Max: 0.9             ✅ NO\n",
       "7           salt_100g    str    Min: 0.0 | Max: 0.99             ✅ NO\n",
       "8         additives_n    str    Min: 0.0 | Max: 0.74             ✅ NO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for col in NUMERICAL_FEATURES:\n",
    "    s = scaler.scalers[col].__class__.__name__\n",
    "    d = X_test_scaled[col]\n",
    "    \n",
    "    # Check if Test data looks \"Suspiciously Perfect\" (Evidence of Leakage)\n",
    "    if s == 'StandardScaler':\n",
    "        # Suspicious if Mean almost 0 AND Std almost 1\n",
    "        is_leaked = np.isclose(d.mean(), 0, atol=0.05) and np.isclose(d.std(), 1, atol=0.02)\n",
    "        stats = \"Mean: \" + str(round(d.mean(), 2)) + \" | Std: \" + str(round(d.std(), 2))\n",
    "        \n",
    "    elif s == 'MinMaxScaler':\n",
    "        # Suspicious if Min almost 0 AND Max almost 1\n",
    "        is_leaked = np.isclose(d.min(), 0, atol=0.01) and np.isclose(d.max(), 1, atol=0.01)\n",
    "        stats = \"Min: \" + str(round(d.min(), 2)) + \" | Max: \" + str(round(d.max(), 2))\n",
    "    data.append({\n",
    "        \"Feature\": col,\n",
    "        \"Scaler\": type(s).__name__,\n",
    "        \"Test Set Stats\": stats,\n",
    "        \"Leakage Detected\": \"⚠️ YES\" if is_leaked else \"✅ NO\"\n",
    "    })\n",
    "\n",
    "print(\"DATA LEAKAGE CHECK (Target: NO for all rows)\")\n",
    "display(pd.DataFrame(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8233",
   "metadata": {},
   "source": [
    "## Observation on Data Leakage Check: False Positives\n",
    "\n",
    "The **\"Leakage Detected\"** warnings reported for specific features (e.g. `sugars_100g`, `fat_100g`, `carbohydrates_100g`) are **false positives** and can be safely ignored.\n",
    "\n",
    "### Reasoning\n",
    "\n",
    "This behavior stems from the **physical nature of nutritional data**, where features are constrained by **hard, known boundaries** (e.g. values between 0 g and 100 g).\n",
    "\n",
    "Because the dataset is sufficiently large, **both the Training Set and the Test Set fully cover the physical range** of these variables, including values at or very close to the minimum and maximum.\n",
    "\n",
    "As a result:\n",
    "\n",
    "- `MinMaxScaler` maps the Test Set bounds to **0.0** and **1.0**\n",
    "- This behavior **mirrors the Training Set scaling**\n",
    "- **No information from the Test Set is leaked into the Training Set**\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The apparent leakage is an **artifact of bounded features**, not a modeling flaw.  \n",
    "The **train/test separation integrity is fully preserved**, and the warnings do **not** indicate real data leakage.\n",
    "\n",
    "This can be seen executing the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f8d3ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with same bounds (Causa of false 'Leakage Detected'):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fat_100g  carbohydrates_100g  sugars_100g\n",
       "min      True                True         True\n",
       "max      True                True         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bounds_train = X_train_scaled[NUMERICAL_FEATURES].agg(['min', 'max'])\n",
    "bounds_test = X_test_scaled[NUMERICAL_FEATURES].agg(['min', 'max'])\n",
    "\n",
    "is_saturated = (bounds_train == bounds_test)\n",
    "\n",
    "print(\"Features with same bounds (Causa of false 'Leakage Detected'):\")\n",
    "display(is_saturated.loc[:, is_saturated.all()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb01cc",
   "metadata": {},
   "source": [
    "## 5. Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6204cf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Scaler loaded: scaler.joblib\n",
      "Method: AUTO\n",
      "Skew threshold: 1.0\n",
      "\n",
      "Scaler distribution:\n",
      "Features scaled: 9\n",
      "\n",
      "Dataset:\n",
      "  Train: 76,905 samples\n",
      "  Test:  19,227 samples\n",
      "\n",
      " Scaling validation completed\n",
      " Ready for model training\n",
      " No leakage detected\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nScaler loaded: {scaler_path.name}\")\n",
    "print(f\"Method: {scaler.method.upper()}\")\n",
    "if scaler.method == 'auto':\n",
    "    print(f\"Skew threshold: {scaler.skew_threshold}\")\n",
    "    print(f\"\\nScaler distribution:\")\n",
    "    from collections import Counter\n",
    "    type_counts = Counter(scaler_types.values())\n",
    "    for stype, count in type_counts.items():\n",
    "        print(f\"  {stype}: {count} features\")\n",
    "print(f\"Features scaled: {len(NUMERICAL_FEATURES)}\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Train: {len(X_train_scaled):,} samples\")\n",
    "print(f\"  Test:  {len(X_test_scaled):,} samples\")\n",
    "print(f\"\\n Scaling validation completed\")\n",
    "print(f\" Ready for model training\")\n",
    "print(f\" No leakage detected\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
